{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05607722,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.05607722,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.05607722,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.05607722,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.05607722,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.05607722,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Load the OTU table file\n",
    "otu_table = pd.read_csv('genus_rotated_f.csv', header=0, index_col=None)\n",
    "\n",
    "X = otu_table.values  # 转换为NumPy数组\n",
    "# 处理标准差为零的情况\n",
    "mean = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "std[std == 0] = 1  # 将标准差为零的特征的标准差设置为1，避免除以零\n",
    "\n",
    "# 数据标准化\n",
    "X = (X - mean) / std\n",
    "\n",
    "# 处理NaN值，将其替换为零或其他合理的数值\n",
    "X = np.nan_to_num(X, nan=0.0)\n",
    "# 数据分割\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Transformer编码器\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, nhead, num_layers, dim_feedforward):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=nhead, dim_feedforward=dim_feedforward)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.linear = nn.Linear(input_dim, input_dim)  # 可选，取决于需要的嵌入维度\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# 掩码数据函数\n",
    "def mask_data(x, mask_ratio=0.15):\n",
    "    mask = np.random.rand(*x.shape) < mask_ratio\n",
    "    x_masked = x.copy()\n",
    "    x_masked[mask] = 0  # 用0填充掩盖的部分\n",
    "    return x_masked, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 超参数设置\n",
    "input_dim = X_train.shape[1]\n",
    "nhead = 3\n",
    "num_layers = 2\n",
    "dim_feedforward = 128\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型初始化\n",
    "model = TransformerEncoder(input_dim, nhead, num_layers, dim_feedforward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # 使用均方误差损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6059686541557312\n",
      "Epoch 2, Loss: 0.5466816425323486\n",
      "Epoch 3, Loss: 0.5837085247039795\n",
      "Epoch 4, Loss: 0.47711533308029175\n",
      "Epoch 5, Loss: 0.4429970681667328\n",
      "Epoch 6, Loss: 0.37490221858024597\n",
      "Epoch 7, Loss: 0.2904721200466156\n",
      "Epoch 8, Loss: 0.26965397596359253\n",
      "Epoch 9, Loss: 0.25968828797340393\n",
      "Epoch 10, Loss: 0.3568226993083954\n",
      "Epoch 11, Loss: 0.3834213316440582\n",
      "Epoch 12, Loss: 0.365933895111084\n",
      "Epoch 13, Loss: 0.3818112015724182\n",
      "Epoch 14, Loss: 0.39016440510749817\n",
      "Epoch 15, Loss: 0.31721505522727966\n",
      "Epoch 16, Loss: 0.2872919738292694\n",
      "Epoch 17, Loss: 0.29132840037345886\n",
      "Epoch 18, Loss: 0.31863150000572205\n",
      "Epoch 19, Loss: 0.31089818477630615\n",
      "Epoch 20, Loss: 0.3327706754207611\n",
      "Epoch 21, Loss: 0.23491650819778442\n",
      "Epoch 22, Loss: 0.33862465620040894\n",
      "Epoch 23, Loss: 0.2721449136734009\n",
      "Epoch 24, Loss: 0.37342599034309387\n",
      "Epoch 25, Loss: 0.2526301443576813\n",
      "Epoch 26, Loss: 0.3040506839752197\n",
      "Epoch 27, Loss: 0.22153881192207336\n",
      "Epoch 28, Loss: 0.2894376516342163\n",
      "Epoch 29, Loss: 0.26523467898368835\n",
      "Epoch 30, Loss: 0.35491296648979187\n",
      "Epoch 31, Loss: 0.2181958258152008\n",
      "Epoch 32, Loss: 0.4203110635280609\n",
      "Epoch 33, Loss: 0.3243747651576996\n",
      "Epoch 34, Loss: 0.3908233940601349\n",
      "Epoch 35, Loss: 0.3799207806587219\n",
      "Epoch 36, Loss: 0.27504217624664307\n",
      "Epoch 37, Loss: 0.339600533246994\n",
      "Epoch 38, Loss: 0.3543044328689575\n",
      "Epoch 39, Loss: 0.30532169342041016\n",
      "Epoch 40, Loss: 0.3097105920314789\n",
      "Epoch 41, Loss: 0.29488885402679443\n",
      "Epoch 42, Loss: 0.28624096512794495\n",
      "Epoch 43, Loss: 0.35923412442207336\n",
      "Epoch 44, Loss: 0.2941342890262604\n",
      "Epoch 45, Loss: 0.33159929513931274\n",
      "Epoch 46, Loss: 0.4204441010951996\n",
      "Epoch 47, Loss: 0.26433277130126953\n",
      "Epoch 48, Loss: 0.3290233612060547\n",
      "Epoch 49, Loss: 0.1982739269733429\n",
      "Epoch 50, Loss: 0.30717992782592773\n",
      "[[-0.34384555  0.06258793 -0.04543352 ...  0.0276721   0.03837533\n",
      "  -0.01860325]\n",
      " [-0.25631627  0.02982285 -0.1502669  ...  0.22525382 -0.02842141\n",
      "  -0.06597902]\n",
      " [-0.3616323   0.05050751 -0.03782354 ...  0.027367    0.04152917\n",
      "  -0.0182907 ]\n",
      " ...\n",
      " [-0.32217205  0.0690363  -0.0420627  ...  0.03380806  0.08572719\n",
      "   0.02869376]\n",
      " [-0.3042583  -0.01928057  0.02633397 ...  0.02926929 -0.02333565\n",
      "  -0.0464324 ]\n",
      " [-0.3438611   0.05823835 -0.05318008 ...  0.04056825  0.03823609\n",
      "  -0.00702328]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 训练模型\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 掩码训练数据\n",
    "    X_train_masked, mask = mask_data(X_train)\n",
    "    \n",
    "    # 将数据转换为tensor\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_train_masked_tensor = torch.tensor(X_train_masked, dtype=torch.float32)\n",
    "    \n",
    "    # 前向传播\n",
    "    outputs = model(X_train_masked_tensor)\n",
    "    \n",
    "    # 计算损失（仅计算掩码部分的损失）\n",
    "    loss = criterion(outputs[mask], X_train_tensor[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# 生成嵌入\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model(torch.tensor(X, dtype=torch.float32))\n",
    "\n",
    "# 将生成的嵌入作为下游任务的输入\n",
    "embeddings = embeddings.numpy()\n",
    "# 绘制损失图像\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
